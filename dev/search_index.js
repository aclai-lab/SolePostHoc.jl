var documenterSearchIndex = {"docs":
[{"location":"getting-started/#getting-started","page":"Getting started","title":"Getting started","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"In this introductory section, you will learn about the main building blocks of SolePostHoc.jl. The above introduces two important ideas for using post-hoc explanation algorithms. Further on in the documentation, the potential of SolePostHoc.jl will become apparent: this package's primary purpose is to provide a uniform interface for knowledge extraction algorithms, enabling the comparison of different post-hoc interpretation methods while maintaining a coherent and intuitive user experience.","category":"page"},{"location":"getting-started/#Fast-introduction","page":"Getting started","title":"Fast introduction","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Consider a machine learning model trained on a generic dataset. For example, let us consider a Random Forest Classifier learned on the Iris dataset to classify 3 different species of flowers. We are interested in extracting interpretable rules that explain the model's decision process. SolePostHoc.jl offers two primary methods for accomplishing this task.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"The first approach is to directly call the specific algorithm function. For example:","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"# Extract rules using the LUMEN algorithm directly\nextracted_rules = lumen(model, X_test, y_test, args...)","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"The second approach uses the unified interface through rule extractors:","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"# Extract rules using the unified interface\nextractor = LumenRuleExtractor()\ndecision_set = modalextractrules(extractor, model, X_test, y_test, args...)","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"The key advantage of the second approach is that it not only executes the original algorithm (equivalent to calling lumen(...) directly) but also converts the output into a DecisionSet. A DecisionSet is a vector of propositional logical rules in Disjunctive Normal Form (DNF), with one rule per class/label.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Consider a trained model that classifies hand gestures. Using SolePostHoc.jl, we might extract the following decision set:","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Class \"Iris-setosa\": IF (SepalLengthCm < -0.5) AND (SepalWidthCm < 8.2) THEN predict \"Iris-setosa\"\nClass \"Iris-versicolor\": IF (SepalLengthCm > 0.5) AND (SepalWidthCm < 3.25) THEN predict \"Iris-versicolor\"\nClass \"Iris-virginica\": IF (PetalWidthCm > 2.0) THEN predict \"Iris-virginica\"","category":"page"},{"location":"getting-started/#Core-definitions","page":"Getting started","title":"Core definitions","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"The foundation of SolePostHoc.jl lies in providing interpretable explanations for complex machine learning models through rule extraction.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"abstract type RuleExtractor","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"A RuleExtractor is an abstract type that defines the interface for all post-hoc explanation algorithms. Each concrete implementation represents a specific knowledge extraction method.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"A DecisionSet represents the extracted knowledge as a collection of logical rules, where each rule corresponds to a specific class or decision outcome in Disjunctive Normal Form.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"The main entry point for rule extraction is:","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"modalextractrules(extractor::RuleExtractor, model, args...)","category":"page"},{"location":"getting-started/#Algorithm-Types","page":"Getting started","title":"Algorithm Types","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"SolePostHoc.jl integrates a wide range of algorithms for knowledge extraction, categorized into three main types:","category":"page"},{"location":"getting-started/#Surrogate-Trees","page":"Getting started","title":"Surrogate Trees","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Algorithms that approximate complex models such as neural networks or random forests with more interpretable decision trees.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"struct REFNERuleExtractor <: RuleExtractor end\nstruct BATreesRuleExtractor <: RuleExtractor end \nstruct TREPANRuleExtractor <: RuleExtractor end","category":"page"},{"location":"getting-started/#Knowledge-Distillation","page":"Getting started","title":"Knowledge Distillation","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Techniques for transferring knowledge from complex models (teacher) to simpler and more transparent ones (student).","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"struct RuleCOSIPLUSRuleExtractor <: RuleExtractor end\nstruct InTreesRuleExtractor <: RuleExtractor end","category":"page"},{"location":"getting-started/#Rule-Extraction","page":"Getting started","title":"Rule Extraction","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Methods for deriving clear and understandable logical rules from any machine learning model.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"struct LUMENRuleExtractor <: RuleExtractor end","category":"page"},{"location":"getting-started/#Direct-Algorithm-Access","page":"Getting started","title":"Direct Algorithm Access","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"For users who prefer to use algorithms in their original form without the unified interface, SolePostHoc.jl provides direct access to each algorithm:","category":"page"},{"location":"getting-started/#SolePostHoc.RuleExtraction.intrees","page":"Getting started","title":"SolePostHoc.RuleExtraction.intrees","text":"intrees(model::Union{AbstractModel,DecisionForest}, X, y::AbstractVector{<:Label}; kwargs...)::DecisionList\n\nReturn a decision list which approximates the behavior of the input model on the specified supervised dataset. The set of relevant and non-redundant rules in the decision list are obtained by means of rule selection, rule pruning, and sequential covering (STEL).\n\nReferences\n\nDeng, Houtao. \"Interpreting tree ensembles with intrees.\" International Journal of Data Science and Analytics 7.4 (2019): 277-287.\n\nKeyword Arguments\n\nprune_rules::Bool=true: access to prune or not\npruning_s::Union{Float64,Nothing}=nothing: parameter that limits the denominator in the pruning metric calculation\npruning_decay_threshold::Union{Float64,Nothing}=nothing: threshold used in pruning to remove or not a joint from the rule\nrule_selection_method::Symbol=:CBC: rule selection method. Currently only supports :CBC\nrule_complexity_metric::Symbol=:natoms: Metric to use for estimating a rule complexity measure\nmax_rules::Int=-1: maximum number of rules in the final decision list (excluding default rule). Use -1 for unlimited rules.\nmin_coverage::Union{Float64,Nothing}=nothing: minimum rule coverage for STEL\nSee modalextractrules keyword arguments...\n\nAlthough the method was originally presented for forests it is hereby extended to work with any symbolic models.\n\nSee also AbstractModel, DecisionList, listrules, rulemetrics.\n\n\n\n\n\n","category":"function"},{"location":"getting-started/#SolePostHoc.RuleExtraction.Lumen.lumen","page":"Getting started","title":"SolePostHoc.RuleExtraction.Lumen.lumen","text":"lumen(model; config_args...) -> LumenResult\nlumen(model, config::LumenConfig) -> LumenResult\n\nLogic-driven Unified Minimal Extractor of Notions (LUMEN): Extract and minimize  logical rules from decision tree models into interpretable DNF formulas.\n\nLUMEN implements a comprehensive pipeline for converting decision tree models into interpretable logical rules. The algorithm extracts the underlying decision logic, constructs truth tables, and applies advanced minimization techniques to produce compact, human-readable rule sets.\n\nMethod Signatures\n\nKeyword Arguments Interface\n\nlumen(model; minimization_scheme=:mitespresso, vertical=1.0, horizontal=1.0, ...)\n\nConvenient interface using keyword arguments with automatic config construction.\n\nConfiguration Object Interface\n\nlumen(model, config::LumenConfig)\n\nAdvanced interface using pre-constructed configuration for complex scenarios.\n\nArguments\n\nRequired Arguments\n\nmodel: Decision tree model to analyze\nSingle trees: Individual decision tree models\nEnsembles: Random forests, gradient boosting, etc.\nSupported formats: DecisionTree.jl, SoleModels framework\n\nConfiguration (via keywords or LumenConfig)\n\nminimization_scheme::Symbol = :mitespresso: DNF minimization algorithm\nvertical::Float64 = 1.0: Instance coverage parameter α ∈ (0,1]\nhorizontal::Float64 = 1.0: Feature coverage parameter β ∈ (0,1]\nott_mode::Bool = false: Enable memory-optimized processing\nsilent::Bool = false: Suppress progress output\nreturn_info::Bool = true: Include detailed metadata in results\n\nReturns\n\nLumenResult containing:\n\ndecision_set: Collection of minimized logical rules\ninfo: Metadata including statistics and unminimized rules\nprocessing_time: Total algorithm execution time\n\nAlgorithm Pipeline\n\nPhase 1: Model Analysis and Rule Extraction\n\nInput Model → Rule Extraction → Logical Rule Set\n\nAnalyzes model structure (single tree vs ensemble)\nExtracts decision paths as logical rules\nHandles different model types with appropriate strategies\n\nPhase 2: Alphabet Construction and Atom Processing\n\nLogical Rules → Atom Extraction → Logical Alphabet\n\nIdentifies atomic logical conditions\nConstructs vocabulary for formula building\nValidates feature support and operator compatibility\n\nPhase 3: Truth Table Generation\n\nModel + Alphabet → Truth Combinations → Labeled Examples\n\nGenerates systematic input combinations\nEvaluates model on each combination\nCreates correspondence between inputs and outputs\n\nPhase 4: DNF Construction and Minimization\n\nTruth Table → DNF Formulas → Minimized Rules\n\nConstructs DNF formulas for each decision class\nApplies advanced minimization algorithms\nConverts back to interpretable rule format\n\nPerformance Characteristics\n\nComputational Complexity\n\nTime: O(2^k × n × d) where k=features, n=instances, d=tree depth\nSpace: O(k × r) where r=number of rules\nScalability: Optimized modes available for large datasets\n\nMemory Usage\n\nStandard mode: Suitable for typical datasets (< 20 features)\nOptimized mode: Memory-efficient processing for large problems\nStreaming capability: Future versions may support streaming processing\n\nAdvanced Features\n\nCustom Processing\n\n# Custom alphabet filtering for domain expertise\ncustom_filter = alphabet -> remove_irrelevant_features(alphabet)\nconfig = LumenConfig(filteralphabetcallback = custom_filter)\nresult = lumen(model, config)\n\nPerformance Tuning\n\n# Memory-optimized processing for large datasets\nconfig = LumenConfig(ott_mode = true, vertical = 0.8)\n\n# Speed-optimized processing with basic minimization\nconfig = LumenConfig(minimization_scheme = :abc, silent = true)\n\nAnalysis and Debugging\n\n# Full information retention for analysis\nconfig = LumenConfig(return_info = true, controllo = true)\nresult = lumen(model, config)\n\n# Access detailed statistics  \nprintln(\"Rules before minimization: _(length(result.info.unminimized_ds.rules))\")\nprintln(\"Rules after minimization: _(length(result.decision_set.rules))\")\n\nError Handling\n\nThe algorithm implements comprehensive error handling:\n\nConfiguration Validation\n\nParameter range checking (coverage parameters must be ∈ (0,1])\nAlgorithm availability verification  \nConsistency validation across parameters\n\nProcessing Errors\n\nGraceful handling of minimization failures\nFallback strategies for problematic formulas\nDetailed error reporting with context\n\nModel Compatibility\n\nAutomatic detection of supported model types\nClear error messages for unsupported formats\nSuggestions for model preprocessing\n\nExamples\n\nBasic Usage\n\n# Simple rule extraction with default settings\nmodel = build_tree(X, y)\nresult = lumen(model)\nprintln(\"Extracted _(length(result.decision_set.rules)) rules\")\n\nAdvanced Configuration\n\n# Customized processing for complex scenarios\nconfig = LumenConfig(\n    minimization_scheme = :boom,        # Aggressive minimization\n    vertical = 0.9,                     # High instance coverage  \n    horizontal = 0.8,                   # Moderate feature coverage\n    ott_mode = true,                    # Memory optimization\n    return_info = true                  # Full information retention\n)\nresult = lumen(large_ensemble, config)\n\nPerformance Analysis\n\n# Detailed performance and quality analysis\nresult = lumen(model, LumenConfig(return_info = true))\n\n# Analyze minimization effectiveness\nstats = result.info.vectPrePostNumber\ntotal_reduction = sum(pre - post for (pre, post) in stats)\navg_compression = mean(pre / post for (pre, post) in stats)\n\nprintln(\"Total term reduction: total_reduction\")\nprintln(\"Average compression ratio: (round(avg_compression, digits=2))x\")\nprintln(\"Processing time: _(result.processing_time) seconds\")\n\nImplementation Notes\n\nDesign Principles\n\nModularity: Each phase is independently testable and extensible\nConfigurability: Extensive customization without code modification\nPerformance: Multiple optimization strategies for different scenarios  \nRobustness: Comprehensive error handling and validation\nUsability: Clean interfaces with sensible defaults\n\nExtensibility Points\n\nNew minimization algorithms: Add via Val() dispatch system\nCustom model types: Extend rule extraction strategies  \nDomain-specific processing: Custom alphabet filters and apply functions\nOutput formats: Additional result formatters and exporters\n\nSee also: LumenConfig, LumenResult, extract_rules, minimize_formula\n\n\n\n\n\n","category":"function"},{"location":"getting-started/#SolePostHoc.RuleExtraction.BATrees.batrees","page":"Getting started","title":"SolePostHoc.RuleExtraction.BATrees.batrees","text":"batrees(f; dataset_name=\"iris\", num_trees=10, max_depth=10, dsOutput=true)\n\nBuilds and trains a set of binary decision trees OR using the specified function f.\n\nArguments\n\nf: An SoleForest.\ndataset_name::String: The name of the dataset to be used. Default is \"iris\".\nnum_trees::Int: The number of trees to be built. Default is 10.\nmax_depth::Int: The maximum depth of each tree. Default is 10.\ndsOutput::Bool: A flag indicating whether to return the dsStruct output. Default is true. if false, returns the result single tree.\n\nReturns\n\nIf dsOutput is true, returns the result is in DecisionSet ds.\nIf dsOutput is false, returns the result is SoleTree t`.\n\nExample\n\n\n\n\n\n","category":"function"},{"location":"getting-started/#SolePostHoc.RuleExtraction.REFNE.refne","page":"Getting started","title":"SolePostHoc.RuleExtraction.REFNE.refne","text":"refne(m, Xmin, Xmax; L=100, perc=1.0, max_depth=-1, n_subfeatures=-1, \n      partial_sampling=0.7, min_samples_leaf=5, min_samples_split=2, \n      min_purity_increase=0.0, seed=3)\n\nExtract interpretable rules from a trained neural network ensemble using decision tree approximation.\n\nThis implementation follows the REFNE-a (Rule Extraction From Neural Network Ensemble) algorithm, which approximates complex neural network behavior with an interpretable decision tree model.\n\nArguments\n\nm: Trained neural network model to extract rules from\nXmin: Minimum values for each input feature\nXmax: Maximum values for each input feature\nL: Number of samples to generate in the synthetic dataset (default: 100)\nperc: Percentage of generated samples to use (default: 1.0)\nmax_depth: Maximum depth of the decision tree (default: -1, unlimited)\nn_subfeatures: Number of features to consider at each split (default: -1, all)\npartial_sampling: Fraction of samples used for each tree (default: 0.7)\nmin_samples_leaf: Minimum number of samples required at a leaf node (default: 5)\nmin_samples_split: Minimum number of samples required to split a node (default: 2)\nmin_purity_increase: Minimum purity increase required for a split (default: 0.0)\nseed: Random seed for reproducibility (default: 3)\n\nReturns\n\nA forest-decision trees representing the extracted rules\n\nDescription\n\nThe algorithm works by:\n\nGenerating a synthetic dataset spanning the input space\nUsing the neural network to label these samples\nTraining a decision tree to approximate the neural network's behavior\n\nReferences\n\nZhi-Hua, Zhou, et al. Extracting Symbolic Rules from Trained Neural Network Ensembles\n\nExample\n\n```julia model = loaddecisiontree_model() refne(model, Xmin, Xmax)\n\nSee also AbstractModel, DecisionList, listrules, rulemetrics.\n\n\n\n\n\n","category":"function"},{"location":"getting-started/#SolePostHoc.RuleExtraction.TREPAN.trepan","page":"Getting started","title":"SolePostHoc.RuleExtraction.TREPAN.trepan","text":"Mark W. Craven, et al. \"Extracting Thee-Structured Representations of Thained Networks\"\n\n\n\n\n\n","category":"function"},{"location":"getting-started/#Rule-Extraction,-simplification-and-Optimization","page":"Getting started","title":"Rule Extraction, simplification and Optimization","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"One of the key features of SolePostHoc.jl is its ability to extract, simplify and optimize extracted rules while maintaining their expressiveness.","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"For example, consider this decision forest:","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"├[1/2]┐ (V3 < 2.45)\n│     ├✔ Iris-setosa\n│     └✘ (V4 < 1.75)\n│       ├✔ (V3 < 4.65)\n│       │ ├✔ Iris-versicolor\n│       │ └✘ Iris-versicolor\n│       └✘ Iris-virginica\n└[2/2]┐ (V4 < 0.8)\n      ├✔ Iris-setosa\n      └✘ (V1 < 5.65)\n        ├✔ (V4 < 1.2)\n        │ ├✔ Iris-versicolor\n        │ └✘ Iris-versicolor\n        └✘ (V3 < 4.75)\n          ├✔ Iris-versicolor\n          └✘ Iris-virginica","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"SolePostHoc.jl can leverage logical reasoning to obtain a more succinct and equally expressive theory:","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"▣\n├[1/3] ((V3 ≥ 2.45) ∧ (V4 ≥ 1.75)) ∨ ((V1 ≥ 5.65) ∧ (V3 ≥ 4.75) ∧ (V4 ≥ 0.8))  ↣  Iris-virginica\n├[2/3] ((V3 ≥ 2.45) ∧ (V3 < 4.65) ∧ (V4 < 1.75)) ∨ ((V3 ≥ 4.65) ∧ (V3 < 4.75) ∧ (V4 < 1.75)) ∨ ((V1 < 5.65) ∧ (V3 ≥ 4.65) ∧ (V4 < 1.75)) ∨ ((V3 ≥ 2.45) ∧ (V4 < 0.8))  ↣  Iris-versicolor\n└[3/3] (V3 < 2.45)  ↣  Iris-setosa\n","category":"page"},{"location":"getting-started/#Customization-and-Extension","page":"Getting started","title":"Customization and Extension","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"Users can implement their own rule extraction algorithms by extending the RuleExtractor interface:","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"\nfunction algorithm(model, args...)\n    # ordinary function\n    return output  # regular generic type of output\nend\n\nstruct MyCustomExtractor <: RuleExtractor\n    # algorithm-specific parameters\nend\n\nfunction modalextractrules(extractor::MyCustomExtractor, model, args...)\n    # implement your custom convert `generic type of output in decision set` logic\n    # return a DecisionSet\nend","category":"page"},{"location":"getting-started/#Integration-with-Sole.jl-Ecosystem","page":"Getting started","title":"Integration with Sole.jl Ecosystem","text":"","category":"section"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"SolePostHoc.jl seamlessly integrates with the broader Sole.jl ecosystem, particularly:","category":"page"},{"location":"getting-started/","page":"Getting started","title":"Getting started","text":"SoleLogics.jl: For modal logic reasoning and formula manipulation\nSoleData.jl: For handling multivariate time series and relational data structures\nSoleModels.jl: For interpretable model training and symbolic learning","category":"page"},{"location":"extract-algorithms/#Rule-Extraction-Methods","page":"Extract with algorithms","title":"Rule Extraction Methods","text":"","category":"section"},{"location":"extract-algorithms/#SolePostHoc.RuleExtraction.intrees-Tuple{Any, Any, AbstractVector{<:Union{AbstractString, Real, Symbol, CategoricalArrays.CategoricalValue}}}","page":"Extract with algorithms","title":"SolePostHoc.RuleExtraction.intrees","text":"intrees(model::Union{AbstractModel,DecisionForest}, X, y::AbstractVector{<:Label}; kwargs...)::DecisionList\n\nReturn a decision list which approximates the behavior of the input model on the specified supervised dataset. The set of relevant and non-redundant rules in the decision list are obtained by means of rule selection, rule pruning, and sequential covering (STEL).\n\nReferences\n\nDeng, Houtao. \"Interpreting tree ensembles with intrees.\" International Journal of Data Science and Analytics 7.4 (2019): 277-287.\n\nKeyword Arguments\n\nprune_rules::Bool=true: access to prune or not\npruning_s::Union{Float64,Nothing}=nothing: parameter that limits the denominator in the pruning metric calculation\npruning_decay_threshold::Union{Float64,Nothing}=nothing: threshold used in pruning to remove or not a joint from the rule\nrule_selection_method::Symbol=:CBC: rule selection method. Currently only supports :CBC\nrule_complexity_metric::Symbol=:natoms: Metric to use for estimating a rule complexity measure\nmax_rules::Int=-1: maximum number of rules in the final decision list (excluding default rule). Use -1 for unlimited rules.\nmin_coverage::Union{Float64,Nothing}=nothing: minimum rule coverage for STEL\nSee modalextractrules keyword arguments...\n\nAlthough the method was originally presented for forests it is hereby extended to work with any symbolic models.\n\nSee also AbstractModel, DecisionList, listrules, rulemetrics.\n\n\n\n\n\n","category":"method"},{"location":"extract-algorithms/#SolePostHoc.RuleExtraction.BATreesRuleExtractor","page":"Extract with algorithms","title":"SolePostHoc.RuleExtraction.BATreesRuleExtractor","text":"Extract rules from a symbolic model using batrees.\n\nSee also modalextractrules, RuleExtractor.\n\n\n\n\n\n","category":"type"},{"location":"extract-algorithms/#SolePostHoc.RuleExtraction.InTreesRuleExtractor","page":"Extract with algorithms","title":"SolePostHoc.RuleExtraction.InTreesRuleExtractor","text":"Extract rules from a symbolic model using intrees.\n\nSee also modalextractrules, RuleExtractor.\n\n\n\n\n\n","category":"type"},{"location":"extract-algorithms/#SolePostHoc.RuleExtraction.LumenRuleExtractor","page":"Extract with algorithms","title":"SolePostHoc.RuleExtraction.LumenRuleExtractor","text":"Extract rules from a symbolic model using lumen.\n\nSee also modalextractrules, RuleExtractor.\n\n\n\n\n\n","category":"type"},{"location":"extract-algorithms/#SolePostHoc.RuleExtraction.REFNERuleExtractor","page":"Extract with algorithms","title":"SolePostHoc.RuleExtraction.REFNERuleExtractor","text":"Extract rules from a symbolic model using SolePostHoc.RuleExtraction.REFNE.\n\nSee also modalextractrules, RuleExtractor.\n\n\n\n\n\n","category":"type"},{"location":"extract-algorithms/#SolePostHoc.RuleExtraction.RULECOSIPLUSRuleExtractor","page":"Extract with algorithms","title":"SolePostHoc.RuleExtraction.RULECOSIPLUSRuleExtractor","text":"Extract rules from a symbolic model using SolePostHoc.RuleExtraction.RULECOSIPLUS.\n\nSee also modalextractrules, RuleExtractor.\n\n\n\n\n\n","category":"type"},{"location":"extract-algorithms/#SolePostHoc.RuleExtraction.TREPANRuleExtractor","page":"Extract with algorithms","title":"SolePostHoc.RuleExtraction.TREPANRuleExtractor","text":"Extract rules from a symbolic model using SolePostHoc.RuleExtraction.TREPAN.\n\nSee also modalextractrules, RuleExtractor.\n\n\n\n\n\n","category":"type"},{"location":"extract-algorithms/#Lumen","page":"Extract with algorithms","title":"Lumen","text":"","category":"section"},{"location":"extract-algorithms/#SolePostHoc.RuleExtraction.Lumen.lumen-Tuple{Any}","page":"Extract with algorithms","title":"SolePostHoc.RuleExtraction.Lumen.lumen","text":"lumen(model; config_args...) -> LumenResult\nlumen(model, config::LumenConfig) -> LumenResult\n\nLogic-driven Unified Minimal Extractor of Notions (LUMEN): Extract and minimize  logical rules from decision tree models into interpretable DNF formulas.\n\nLUMEN implements a comprehensive pipeline for converting decision tree models into interpretable logical rules. The algorithm extracts the underlying decision logic, constructs truth tables, and applies advanced minimization techniques to produce compact, human-readable rule sets.\n\nMethod Signatures\n\nKeyword Arguments Interface\n\nlumen(model; minimization_scheme=:mitespresso, vertical=1.0, horizontal=1.0, ...)\n\nConvenient interface using keyword arguments with automatic config construction.\n\nConfiguration Object Interface\n\nlumen(model, config::LumenConfig)\n\nAdvanced interface using pre-constructed configuration for complex scenarios.\n\nArguments\n\nRequired Arguments\n\nmodel: Decision tree model to analyze\nSingle trees: Individual decision tree models\nEnsembles: Random forests, gradient boosting, etc.\nSupported formats: DecisionTree.jl, SoleModels framework\n\nConfiguration (via keywords or LumenConfig)\n\nminimization_scheme::Symbol = :mitespresso: DNF minimization algorithm\nvertical::Float64 = 1.0: Instance coverage parameter α ∈ (0,1]\nhorizontal::Float64 = 1.0: Feature coverage parameter β ∈ (0,1]\nott_mode::Bool = false: Enable memory-optimized processing\nsilent::Bool = false: Suppress progress output\nreturn_info::Bool = true: Include detailed metadata in results\n\nReturns\n\nLumenResult containing:\n\ndecision_set: Collection of minimized logical rules\ninfo: Metadata including statistics and unminimized rules\nprocessing_time: Total algorithm execution time\n\nAlgorithm Pipeline\n\nPhase 1: Model Analysis and Rule Extraction\n\nInput Model → Rule Extraction → Logical Rule Set\n\nAnalyzes model structure (single tree vs ensemble)\nExtracts decision paths as logical rules\nHandles different model types with appropriate strategies\n\nPhase 2: Alphabet Construction and Atom Processing\n\nLogical Rules → Atom Extraction → Logical Alphabet\n\nIdentifies atomic logical conditions\nConstructs vocabulary for formula building\nValidates feature support and operator compatibility\n\nPhase 3: Truth Table Generation\n\nModel + Alphabet → Truth Combinations → Labeled Examples\n\nGenerates systematic input combinations\nEvaluates model on each combination\nCreates correspondence between inputs and outputs\n\nPhase 4: DNF Construction and Minimization\n\nTruth Table → DNF Formulas → Minimized Rules\n\nConstructs DNF formulas for each decision class\nApplies advanced minimization algorithms\nConverts back to interpretable rule format\n\nPerformance Characteristics\n\nComputational Complexity\n\nTime: O(2^k × n × d) where k=features, n=instances, d=tree depth\nSpace: O(k × r) where r=number of rules\nScalability: Optimized modes available for large datasets\n\nMemory Usage\n\nStandard mode: Suitable for typical datasets (< 20 features)\nOptimized mode: Memory-efficient processing for large problems\nStreaming capability: Future versions may support streaming processing\n\nAdvanced Features\n\nCustom Processing\n\n# Custom alphabet filtering for domain expertise\ncustom_filter = alphabet -> remove_irrelevant_features(alphabet)\nconfig = LumenConfig(filteralphabetcallback = custom_filter)\nresult = lumen(model, config)\n\nPerformance Tuning\n\n# Memory-optimized processing for large datasets\nconfig = LumenConfig(ott_mode = true, vertical = 0.8)\n\n# Speed-optimized processing with basic minimization\nconfig = LumenConfig(minimization_scheme = :abc, silent = true)\n\nAnalysis and Debugging\n\n# Full information retention for analysis\nconfig = LumenConfig(return_info = true, controllo = true)\nresult = lumen(model, config)\n\n# Access detailed statistics  \nprintln(\"Rules before minimization: _(length(result.info.unminimized_ds.rules))\")\nprintln(\"Rules after minimization: _(length(result.decision_set.rules))\")\n\nError Handling\n\nThe algorithm implements comprehensive error handling:\n\nConfiguration Validation\n\nParameter range checking (coverage parameters must be ∈ (0,1])\nAlgorithm availability verification  \nConsistency validation across parameters\n\nProcessing Errors\n\nGraceful handling of minimization failures\nFallback strategies for problematic formulas\nDetailed error reporting with context\n\nModel Compatibility\n\nAutomatic detection of supported model types\nClear error messages for unsupported formats\nSuggestions for model preprocessing\n\nExamples\n\nBasic Usage\n\n# Simple rule extraction with default settings\nmodel = build_tree(X, y)\nresult = lumen(model)\nprintln(\"Extracted _(length(result.decision_set.rules)) rules\")\n\nAdvanced Configuration\n\n# Customized processing for complex scenarios\nconfig = LumenConfig(\n    minimization_scheme = :boom,        # Aggressive minimization\n    vertical = 0.9,                     # High instance coverage  \n    horizontal = 0.8,                   # Moderate feature coverage\n    ott_mode = true,                    # Memory optimization\n    return_info = true                  # Full information retention\n)\nresult = lumen(large_ensemble, config)\n\nPerformance Analysis\n\n# Detailed performance and quality analysis\nresult = lumen(model, LumenConfig(return_info = true))\n\n# Analyze minimization effectiveness\nstats = result.info.vectPrePostNumber\ntotal_reduction = sum(pre - post for (pre, post) in stats)\navg_compression = mean(pre / post for (pre, post) in stats)\n\nprintln(\"Total term reduction: total_reduction\")\nprintln(\"Average compression ratio: (round(avg_compression, digits=2))x\")\nprintln(\"Processing time: _(result.processing_time) seconds\")\n\nImplementation Notes\n\nDesign Principles\n\nModularity: Each phase is independently testable and extensible\nConfigurability: Extensive customization without code modification\nPerformance: Multiple optimization strategies for different scenarios  \nRobustness: Comprehensive error handling and validation\nUsability: Clean interfaces with sensible defaults\n\nExtensibility Points\n\nNew minimization algorithms: Add via Val() dispatch system\nCustom model types: Extend rule extraction strategies  \nDomain-specific processing: Custom alphabet filters and apply functions\nOutput formats: Additional result formatters and exporters\n\nSee also: LumenConfig, LumenResult, extract_rules, minimize_formula\n\n\n\n\n\n","category":"method"},{"location":"extract-algorithms/#SolePostHoc.RuleExtraction.Lumen.LumenConfig","page":"Extract with algorithms","title":"SolePostHoc.RuleExtraction.Lumen.LumenConfig","text":"LumenConfig\n\nConfiguration parameters for the Logic-driven Unified Minimal Extractor of Notions (LUMEN) algorithm.\n\nThis struct encapsulates all configuration options for the LUMEN algorithm, providing a clean interface with automatic validation and sensible defaults. It uses Julia's @kwdef macro to enable keyword-based construction with default values.\n\nFields\n\nCore Algorithm Parameters\n\nminimization_scheme::Symbol = :AlgorithmName: The DNF minimization algorithm to use\n:mitespresso: Advanced minimization with good balance of speed/quality\n:boom: Boom minimizator \n:abc: Minimization whit Berkeley framework \n\nCoverage Parameters\n\nvertical::Float64 = 1.0: Vertical coverage parameter (α) ∈ (0.0, 1.0] Controls how many instances must be covered by extracted rules\nhorizontal::Float64 = 1.0: Horizontal coverage parameter (β) ∈ (0.0, 1.0]   Controls the breadth of rule coverage across feature space (% of different thresholds)\n\nProcessing Modes\n\nott_mode::Bool = false: Optimized truth table processing When true, uses memory-efficient and time-efficient algorithms for large datasets\ncontrollo::Bool = false: Enable validation mode Compares results between different processing methods for correctness verification\n\nCustomization Options\n\nminimization_kwargs::NamedTuple = (;): Additional parameters for minimization algorithms\nfilteralphabetcallback = identity: Custom function to filter/modify the logical alphabet\napply_function = nothing: Custom function for model application If nothing, automatically determined based on model type (with SoleModels)\n\nOutput Control\n\nsilent::Bool = false: Suppress progress and diagnostic output\nreturn_info::Bool = true: Include additional metadata in results\nvetImportance::Vector = []: Vector for tracking feature importance values\n\nTesting and Debugging\n\ntestott = nothing: Special testing mode for optimization validation\nalphabetcontroll = nothing: Special mode for alphabet analysis only\n\nConstructor Validation\n\nThe constructor automatically validates parameters and throws descriptive errors:\n\nCoverage parameters must be in range (0.0, 1.0]\nMinimization scheme must be supported\nInconsistent parameter combinations are caught early\n\nExamples\n\n# Basic usage with defaults\nconfig = LumenConfig()\n\n# Customized configuration\nconfig = LumenConfig(\n    minimization_scheme = :abc,\n    vertical = 0.8,\n    horizontal = 0.9,\n    silent = true\n)\n\n# Advanced configuration with custom processing\nconfig = LumenConfig(\n    ott_mode = true,\n    minimization_kwargs = (max_iterations = 1000,),\n    filteralphabetcallback = my_custom_filter\n)\n\nSee also: lumen, LumenResult, validate_config\n\n\n\n\n\n","category":"type"},{"location":"extract-algorithms/#SolePostHoc.RuleExtraction.Lumen.LumenResult","page":"Extract with algorithms","title":"SolePostHoc.RuleExtraction.Lumen.LumenResult","text":"LumenResult\n\nComprehensive result structure containing extracted logical rules and associated metadata.\n\nThis immutable struct encapsulates all outputs from the LUMEN algorithm, providing a clean and extensible interface for accessing results. The design follows the principle of  returning rich, self-documenting results rather than simple tuples.\n\nFields\n\ndecision_set::DecisionSet: The primary output - a collection of minimized logical rules Each rule consists of a logical formula (antecedent) and a decision outcome (consequent)\ninfo::NamedTuple: Extensible metadata container with algorithm-specific information Common fields include:\nvectPrePostNumber: Vector of (pre, post) minimization term counts\nunminimized_ds: Original decision set before minimization (if requested)\nprocessing_time: Total algorithm execution time\nfeature_importance: Feature ranking information (if available)\nprocessing_time::Float64: Total processing time in seconds Measured from algorithm start to completion, useful for performance analysis\n\nConstructors\n\nTwo constructors are provided for different use cases:\n\n# Full constructor - for complete results with metadata\nLumenResult(decision_set, info_tuple, processing_time)\n\n# Minimal constructor - when only rules are available  \nLumenResult(decision_set)  # info=empty, processing_time=0.0\n\nDesign Rationale\n\nThis structured approach provides several advantages over returning raw tuples:\n\nSelf-documentation: Field names clearly indicate content\nType safety: Julia's type system validates structure at compile time  \nExtensibility: Easy to add new fields without breaking existing code\nIDE support: Autocompletion and inline documentation\nBackward compatibility: Old code can still access fields by name\n\nExamples\n\n# Basic usage\nresult = lumen(model, config)\nrules = result.decision_set\nprintln(\"Extracted (length(rules.rules)) rules in (result.processing_time)s\")\n\n# Accessing metadata\nif haskey(result.info, :vectPrePostNumber)\n    stats = result.info.vectPrePostNumber\n    total_reduction = sum(pre - post for (pre, post) in stats)\n    println(\"Reduced formula complexity by \total_reduction terms\")\nend\n\n# Comparing minimized vs original rules\nif haskey(result.info, :unminimized_ds)\n    original_rules = result.info.unminimized_ds\n    println(\"Minimization: (length(original_rules.rules)) → (length(result.decision_set.rules))\")\nend\n\nSee also: lumen, LumenConfig, DecisionSet\n\n\n\n\n\n","category":"type"},{"location":"extract-algorithms/#REFNE","page":"Extract with algorithms","title":"REFNE","text":"","category":"section"},{"location":"extract-algorithms/#SolePostHoc.RuleExtraction.REFNE.refne-Tuple{Any, Any, Any}","page":"Extract with algorithms","title":"SolePostHoc.RuleExtraction.REFNE.refne","text":"refne(m, Xmin, Xmax; L=100, perc=1.0, max_depth=-1, n_subfeatures=-1, \n      partial_sampling=0.7, min_samples_leaf=5, min_samples_split=2, \n      min_purity_increase=0.0, seed=3)\n\nExtract interpretable rules from a trained neural network ensemble using decision tree approximation.\n\nThis implementation follows the REFNE-a (Rule Extraction From Neural Network Ensemble) algorithm, which approximates complex neural network behavior with an interpretable decision tree model.\n\nArguments\n\nm: Trained neural network model to extract rules from\nXmin: Minimum values for each input feature\nXmax: Maximum values for each input feature\nL: Number of samples to generate in the synthetic dataset (default: 100)\nperc: Percentage of generated samples to use (default: 1.0)\nmax_depth: Maximum depth of the decision tree (default: -1, unlimited)\nn_subfeatures: Number of features to consider at each split (default: -1, all)\npartial_sampling: Fraction of samples used for each tree (default: 0.7)\nmin_samples_leaf: Minimum number of samples required at a leaf node (default: 5)\nmin_samples_split: Minimum number of samples required to split a node (default: 2)\nmin_purity_increase: Minimum purity increase required for a split (default: 0.0)\nseed: Random seed for reproducibility (default: 3)\n\nReturns\n\nA forest-decision trees representing the extracted rules\n\nDescription\n\nThe algorithm works by:\n\nGenerating a synthetic dataset spanning the input space\nUsing the neural network to label these samples\nTraining a decision tree to approximate the neural network's behavior\n\nReferences\n\nZhi-Hua, Zhou, et al. Extracting Symbolic Rules from Trained Neural Network Ensembles\n\nExample\n\n```julia model = loaddecisiontree_model() refne(model, Xmin, Xmax)\n\nSee also AbstractModel, DecisionList, listrules, rulemetrics.\n\n\n\n\n\n","category":"method"},{"location":"extract-algorithms/#TREPAN","page":"Extract with algorithms","title":"TREPAN","text":"","category":"section"},{"location":"extract-algorithms/#SolePostHoc.RuleExtraction.TREPAN.trepan-Tuple{Any, Any}","page":"Extract with algorithms","title":"SolePostHoc.RuleExtraction.TREPAN.trepan","text":"Mark W. Craven, et al. \"Extracting Thee-Structured Representations of Thained Networks\"\n\n\n\n\n\n","category":"method"},{"location":"extract-algorithms/#BATrees","page":"Extract with algorithms","title":"BATrees","text":"","category":"section"},{"location":"extract-algorithms/#SolePostHoc.RuleExtraction.BATrees.batrees","page":"Extract with algorithms","title":"SolePostHoc.RuleExtraction.BATrees.batrees","text":"batrees(f; dataset_name=\"iris\", num_trees=10, max_depth=10, dsOutput=true)\n\nBuilds and trains a set of binary decision trees OR using the specified function f.\n\nArguments\n\nf: An SoleForest.\ndataset_name::String: The name of the dataset to be used. Default is \"iris\".\nnum_trees::Int: The number of trees to be built. Default is 10.\nmax_depth::Int: The maximum depth of each tree. Default is 10.\ndsOutput::Bool: A flag indicating whether to return the dsStruct output. Default is true. if false, returns the result single tree.\n\nReturns\n\nIf dsOutput is true, returns the result is in DecisionSet ds.\nIf dsOutput is false, returns the result is SoleTree t`.\n\nExample\n\n\n\n\n\n","category":"function"},{"location":"extract-algorithms/#RULECOSIPLUS","page":"Extract with algorithms","title":"RULECOSIPLUS","text":"","category":"section"},{"location":"contributing/#ModalAssociationRules.jl","page":"Contributing","title":"ModalAssociationRules.jl","text":"","category":"section"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"The package is developed by the ACLAI Lab @ University of Ferrara.","category":"page"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"ModalAssociationRules.jl lives in the context of Sole.jl, an open-source framework for symbolic machine learning, originally designed for machine learning based on modal logics (see Eduard I. Stan's PhD thesis \"Foundations of Modal Symbolic Learning\" here).","category":"page"},{"location":"contributing/#Algorithm-References","page":"Contributing","title":"Algorithm References","text":"","category":"section"},{"location":"contributing/#Intrees","page":"Contributing","title":"Intrees","text":"","category":"section"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"Deng, H. (2019). Interpreting tree ensembles with intrees. International Journal of Data Science and Analytics, 7(4), 277-287.","category":"page"},{"location":"contributing/#Born-Again-Tree","page":"Contributing","title":"Born-Again Tree","text":"","category":"section"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"Breiman, L. Born AgainTrees. Unpublished. Available at: https://www.stat.berkeley.edu/\nThibaut, V. Born-Again Tree Ensembles. arXiv preprint. Available at: https://arxiv.org/pdf/2003.11132","category":"page"},{"location":"contributing/#RuleCosi","page":"Contributing","title":"RuleCosi+","text":"","category":"section"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"Obregon, J. (2022). RuleCOSI+: Rule extraction for interpreting classification tree ensembles. Information Fusion, 89, 355-381. Available at: https://www.sciencedirect.com/science/article/pii/S1566253522001129","category":"page"},{"location":"contributing/#REFNE","page":"Contributing","title":"REFNE","text":"","category":"section"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"Zhou, Z. (2003). Extracting Symbolic Rules from Trained Neural Network Ensembles. AI Communications, 16, 3-15.","category":"page"},{"location":"contributing/#TREPAN","page":"Contributing","title":"TREPAN","text":"","category":"section"},{"location":"contributing/","page":"Contributing","title":"Contributing","text":"Craven, M. (1995). Extracting Tree-Structured Representations of Trained Networks. In Proceedings of the 8th Annual Conference on Advances in Neural Information Processing Systems (Vol. 8, pp. 25-30).","category":"page"},{"location":"#SolePostHoc","page":"Home","title":"SolePostHoc","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Welcome!!! to the documentation for SolePostHoc.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install SolePostHoc, simply launch:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"SolePostHoc\")","category":"page"},{"location":"#feature","page":"Home","title":"Feature","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"SolePostHoc.jl provides knowledge extraction algorithms through a uniform interface, allowing for the comparison of different post-hoc interpretation methods while maintaining a coherent and intuitive user experience:","category":"page"},{"location":"","page":"Home","title":"Home","text":"struct ALGORITHMNAME <: RuleExtractor end\nmodalextractrules(:ALGORITHMNAME, model, args...)","category":"page"},{"location":"","page":"Home","title":"Home","text":"SolePostHoc.jl integrates a wide range of algorithms for knowledge extraction, including:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Surrogate Trees, algorithms that approximate complex models such as neural networks or random forests with more interpretable decision trees;\nKnowledge Distillation, techniques for transferring knowledge from complex models to simpler and more transparent ones;\nRule Extraction, methods for deriving clear and understandable logical rules from any machine learning model.","category":"page"},{"location":"#About","page":"Home","title":"About","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The package is developed by the ACLAI Lab @ University of Ferrara.","category":"page"},{"location":"","page":"Home","title":"Home","text":"ModalAssociationRules.jl lives in the context of Sole.jl, an open-source framework for symbolic machine learning, originally designed for machine learning based on modal logics (see Eduard I. Stan's PhD thesis 'Foundations of Modal Symbolic Learning' here).","category":"page"}]
}
